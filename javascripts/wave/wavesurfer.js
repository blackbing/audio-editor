// Generated by CoffeeScript 1.3.3
(function() {

  define(function(require) {
    var Drawer, WaveSurfer, WaveTrack, WebAudio, exports;
    WebAudio = require('../lib/webaudio');
    Drawer = require('./drawer');
    WaveTrack = require('./wavetrack');
    WaveSurfer = {
      init: function(params) {
        var _this = this;
        this.webAudio = WebAudio;
        this.webAudio.init(params);
        this.drawer = Drawer;
        this.drawer.init(params);
        return this.webAudio.proc.onaudioprocess = function() {
          return _this.onAudioProcess();
        };
        /*
              @drawer.bindClick (percents)=>
                @playAt percents
        */

      },
      onAudioProcess: function() {
        if (!this.webAudio.paused) {
          return this.updatePercents();
        }
      },
      updatePercents: function() {
        var d, percents;
        d = this.webAudio.ac.currentTime - this.webAudio.lastPlay;
        percents = d / this.webAudio.getDuration();
        return this.currentPercents = this.lastPlayPercents + percents;
      },
      playAt: function(percents) {
        this.webAudio.play(this.webAudio.getDuration() * percents);
        return this.lastPlayPercents = percents;
      },
      pause: function() {
        this.webAudio.pause();
        return this.updatePercents();
      },
      playPause: function() {
        if (this.webAudio.paused) {
          return this.playAt(this.currentPercents || 0);
        } else {
          return this.pause();
        }
      },
      setSelection: function() {},
      getSelection: function() {},
      "export": function() {
        var c, chan, cn, currentBuffer, sequenceList, waveTrack, _i, _len;
        waveTrack = new WaveTrack();
        sequenceList = [];
        currentBuffer = this.webAudio.currentBuffer;
        c = 0;
        while (c < currentBuffer.numberOfChannels) {
          chan = currentBuffer.getChannelData(c);
          console.log(chan);
          chan.data = [];
          chan.sampleRate = currentBuffer.sampleRate;
          for (_i = 0, _len = chan.length; _i < _len; _i++) {
            cn = chan[_i];
            chan.data.push(cn);
          }
          chan.data = chan.data.slice(chan.data.length / 2, chan.data.length);
          sequenceList.push(chan);
          c++;
        }
        console.log(currentBuffer);
        console.log(sequenceList);
        waveTrack.fromAudioSequences(sequenceList);
        console.log(waveTrack);
        return console.log(waveTrack.toBlobUrlAsync("application/octet-stream"));
      },
      draw: function() {
        return this.drawer.drawBuffer(this.webAudio.currentBuffer);
      },
      load: function(src) {
        var self, xhr;
        self = this;
        xhr = new XMLHttpRequest();
        xhr.responseType = "arraybuffer";
        xhr.onload = function() {
          return self.webAudio.loadData(xhr.response, self.draw.bind(self));
        };
        xhr.open("GET", src, true);
        return xhr.send();
      },
      loadFile: function(file) {
        var reader, self;
        self = this;
        reader = new FileReader();
        reader.addEventListener("load", (function(e) {
          return self.webAudio.loadData(e.target.result, self.draw.bind(self));
        }), false);
        return reader.readAsArrayBuffer(file);
      },
      bindDragNDrop: function(dropTarget) {
        var reader, self;
        self = this;
        reader = new FileReader();
        reader.addEventListener("load", (function(e) {
          return self.webAudio.loadData(e.target.result, self.draw.bind(self));
        }), false);
        return (dropTarget || document).addEventListener("drop", (function(e) {
          var file;
          e.preventDefault();
          file = e.dataTransfer.files[0];
          return file && reader.readAsArrayBuffer(file);
        }), false);
      }
    };
    return exports = WaveSurfer;
  });

}).call(this);
